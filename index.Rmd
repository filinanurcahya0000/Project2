---
title: 'Project 2: Data Mining, Classification, Prediction'
author: "SDS322E : Elements of Data Science"
date: ''
output:
  html_document:
    toc: yes
    toc_float:
      collapsed: no
      smooth_scroll: yes
  pdf_document:
    toc: no
---

```{r setup, include=FALSE}
knitr::opts_chunk$set(echo = TRUE, eval = TRUE, fig.align = "center", warning = F, message = F,
tidy=TRUE, tidy.opts=list(width.cutoff=60), R.options=list(max.print=100))
class_diag <- function(score, truth, positive, cutoff=.5){
  pred <- factor(score>cutoff,levels=c("TRUE","FALSE"))
  truth <- factor(truth==positive, levels=c("TRUE","FALSE"))
  tab<-table(truth, pred)
  acc=sum(diag(tab))/sum(tab)
  sens=tab[1,1]/rowSums(tab)[1]
  spec=tab[2,2]/rowSums(tab)[2]
  ppv=tab[1,1]/colSums(tab)[1]
#CALCULATE F1
  f1=2*(sens*ppv)/(sens+ppv)
  
#CALCULATE EXACT AUC
  truth<-as.numeric(truth=="TRUE")
  ord<-order(score, decreasing=TRUE)
  score <- score[ord]; truth <- truth[ord]
  TPR=cumsum(truth)/max(1,sum(truth))
  FPR=cumsum(!truth)/max(1,sum(!truth))
  dup<-c(score[-1]>=score[-length(score)], FALSE)
  TPR<-c(0,TPR[!dup],1); FPR<-c(0,FPR[!dup],1)
  n <- length(TPR)
  auc<- sum( ((TPR[-1]+TPR[-n])/2) * (FPR[-1]-FPR[-n]) )
  round(data.frame(acc,sens,spec,ppv,f1,ba=(sens+spec)/2,auc, row.names = "Metrics"),4)
}
```

## Filina Nurcahya-Tjoa UTEID : fnt226

For this project, I'm going to use the same data set as I used in my first project. However, instead of focusing on COVID related variables, I'm going to focus on how the population is affected by various factors related to wealth and resources. These datasets were collected in the year of 2020. They are a total of 51 observations. I got my data set from Kaggle. 

The variables I'm going to focus on are :

Population - The number of people that live in a particular state. 

Gini - A measure of how wealth is distributed within a population. The higher the value, the more wealth inequality exists. 

ICU Beds - The number of beds in the ICU available within each state. 

Income - The average income for a household in each state. 

GDP (Gross Domestic Product) - The monetary value of all finished goods and services made within a state during a specific period. Could be used as a measure of growth and productivity. 

I also created a new variable called "Pop.Density.Level" where states with a population density of over a hundred are considered a "high" population density state while states with population densities less than a hundred are considered a "low" population density state. These are denoted with a 1 and 0 respectively. There are 27 "high" population density states and 24 "low" population density states. 

```{R}
library(tidyverse)
library(gt)
library(caret)

dataset <- read.csv("COVID19_state.csv") 
dataset <- dataset %>% select(1:10)
dataset <- dataset %>% mutate(Pop.Density.Level = case_when(Pop.Density > 100 ~ "1", Pop.Density < 100 ~ "0"))
sum(dataset$Pop.Density.Level == 1)
sum(dataset$Pop.Density.Level == 0)
rownames(dataset) <- dataset$State
dataset <- dataset %>% select(-c(Pop.Density, Infected, Deaths, State))

```

### Clustering 

```{R}
library(cluster)
library(GGally)

# Selecting Variables to Cluster
pam_data <- dataset %>% select(Tested, Income, GDP)

# Finding the Suggested Number of Clusters. 
sil_width <- vector()

for(i in 2:10) {  
  pam_fit <- pam(pam_data, k = i)  
  sil_width[i] <- pam_fit$silinfo$avg.width }
ggplot() + geom_line(aes(x = 1:10, y = sil_width)) + scale_x_continuous(name = "k", breaks = 1:10)

# Performing Clustering 
pam1 <- pam_data %>% pam(2)
pam1 %>% head(6)

pam_data %>% slice(pam1$id.med)

# Visualize the Data using GGpairs. 

ggpairs(pam_data, columns = 1:3, aes(color = as.factor(pam1$clustering)))

pamclust <- pam_data %>% mutate(cluster = as.factor(pam1$clustering))
pamclust %>% ggplot(aes(Tested, Income, color = GDP, shape = cluster)) + geom_point(size = 1) 

# Silhouette Plot of Model.

pam1$silinfo$avg.width %>% head(6)
plot(pam1, which = 2)

# Clustering based on Gower Dissimilarities. 
gower_data <- dataset %>% select(Income, Tested, GDP, Pop.Density.Level)
gower_data$Pop.Density.Level <- as.factor(gower_data$Pop.Density.Level)

gower <- daisy(gower_data, metric = "gower")

silwidth <- vector()

for(i in 2:10){  
  pam_fit <- pam(gower, diss = TRUE, k = i)  
  sil_width[i] <- pam_fit$silinfo$avg.width }

ggplot() + geom_line(aes(x = 1:10, y = sil_width)) + scale_x_continuous(name = "k", breaks = 1:10)

pam1 <- pam(gower, k = 2, diss = T)
pam1 %>% head(6)

gower_data %>% slice(pam1$id.med)

pam1$silinfo$widths %>% head(6)
plot(pam1, which = 2)
```

In this clustering analysis, I wanted to see which states were most similar in terms of Income, GDP, and Testing Numbers. We found from the silhouette width that the optimal number of clusters are two. 

We found that the medoid of the first cluster is Alabama and the medoid of the second cluster is Texas. That means that these states are the most representative of their cluster. This result is surprising as these states are both similar geographically and culturally. 

By using ggpairs plot, we found that overall there is a positive correlation (but not significant) between income, testing numbers, and GDP. However, it is important to take into account that cluster one has a slightly negative correlation between GDP and testing level which deviates from the overall trend. In cluster two, income and GDP has a highly significant positive relationship.

Our model was an average silhouette width of 0.74 which means that our model has a strong structure which is good! 

Next, we used Gower's differences to add "Pop.Density.Level" into our cluster analysis. We also found that two clusters are the optimal number clusters. We found that the medoid of the first cluster is Nevada and the medoid of the second cluster is Wisconsin. This model has an average silhouette width of 0.7 which means a reasonable structure has been found. That means that adding the variable added error into the analysis.

### Dimensionality Reduction with PCA

```{R}
PCA_data <- dataset %>% select(Income, Gini, GDP) %>% select_if(is.numeric) %>% scale

pca1 <- princomp(PCA_data)
names(pca1)

summary(pca1, loadings = T)

# Choosing how many PCs to keep. (It seems like 2 PCs should be kept.)
eigval <- pca1$sdev^2
varprop = round(eigval/sum(eigval), 2) 

ggplot() + geom_bar(aes(y = varprop, x = 1:3), stat = "identity") + xlab("") + 
geom_text(aes(x=1:3, y=varprop, label=round(varprop, 2)), vjust=1, col="white", size=5) + scale_y_continuous(breaks=seq(0, .6, .2), labels = scales::percent) + scale_x_continuous(breaks = 1:10)

round(cumsum(eigval)/sum(eigval), 2)
eigval

# Plot of PC Scores. 
PCA_data <- as.data.frame(PCA_data)
PCA_data$Pop.Density.Level <- dataset$Pop.Density.Level
PCA_data$Pop.Density.Level <- ifelse(PCA_data$Pop.Density.Level == 1, "High", "Low")
PCA_data %>% mutate(PC1 = pca1$scores[, 1], PC2 = pca1$scores[, 2]) %>% 
ggplot(aes(PC1, PC2, color = Pop.Density.Level)) + geom_point() + coord_fixed()

# Plotting Loadings.

pca1$loadings[1:3, 1:2] %>% as.data.frame %>% rownames_to_column %>% 
ggplot() + geom_hline(aes(yintercept = 0), lty = 2) + 
geom_vline(aes(xintercept = 0), lty = 2) + ylab("PC2") + xlab("PC1") + 
geom_segment(aes(x = 0, y = 0, xend = Comp.1, yend = Comp.2), arrow = arrow(), col = "red") + geom_label(aes(x = Comp.1*1.1, y = Comp.2*1.1, label = rowname))

library(factoextra)
fviz_pca_biplot(pca1, col.ind = PCA_data$Pop.Density.Level, geom = "text", labelsize = 2) + theme_minimal()
```

I found from looking at the eigenvalues and variance percentages that the optimal number of PCs to retain is 2 (the scree plot doesn't flatten out). By choosing two PCs, the model accounts for 84% of the variance in the data which means it is a pretty good model. 

By looking at the summary of the PC object, we found that the first PC is a general financial strength axis with all the variables in the column having a positive correlation. The second PC is an Income vs Gini scale which is uncorrelated to GDP. High income scores mean low Gini scores and vice versa. 

When plotting the PC scores, we find that PC1 separates between population density level while PC2 doesn't. From the PCA biplot, we can see that all these variables are correlated in the first dimension but not the second. We can also see that the high population density states are dispersed more to the left of the plot than the low population states.  

### Linear Classifier and Cross-Validation

```{R}
library(caret)

Logregressiondata <- dataset %>% select(-Population)

# Logistic Regression on Dataset. 

Logregressiondata$Pop.Density.Level <- as.numeric(Logregressiondata$Pop.Density.Level)
fit <- glm(Pop.Density.Level ~ Income + Gini + ICU.Beds + Income + GDP, data = Logregressiondata, family = binomial)
summary(fit)

score <- predict(fit, type = "response")
head(score)

class_diag(score, dataset$Pop.Density.Level, positive = 1)

# Confusion Matrix. 

Logregressiondata$Pop.Density.Level <- ifelse(dataset$Pop.Density.Level == 1 , TRUE, FALSE)
Logregressiondata$Pop.Density.Level <- as.factor(Logregressiondata$Pop.Density.Level)
pdata <- predict(fit, newdata = Logregressiondata, type = "response")
table(data = pdata > 0.5, reference = Logregressiondata$Pop.Density.Level) 

# K-Fold CV. 

Logregressiondata$Pop.Density.Level <- ifelse(Logregressiondata$Pop.Density.Level == TRUE, 1, 0)
Logregressiondata$Pop.Density.Level <- as.numeric(Logregressiondata$Pop.Density.Level)

k = 5
data <- Logregressiondata[sample(nrow(Logregressiondata)),] 
folds <- cut(seq(1:nrow(Logregressiondata)), breaks = k, labels = F) 
diags <- NULL

for(i in 1:k){
  train <- data[folds!=i,] 
  test <- data[folds==i,]
  truth <- test$Pop.Density.Level
  fit <- glm(Pop.Density.Level ~ Income + Gini + ICU.Beds + GDP, data = train, family = binomial)
  probs <- predict(fit, newdata = test, type = "response")
  diags <- rbind(diags, class_diag(probs, truth, positive = 1))
}

summarize_all(diags, mean)

```

When predicting the data using logistic regression, we get an AUC value of around 0.90. When predicting the data using K-Fold CV, we get an AUC value of around 0.87. Since the AUC values are so similar, there seems to be no signs of over fitting. My model is a strong predictor of new observations. From our confusion matrix, we can see that the majority of the predictions are correct.

### Non-Parametric Classifier and Cross-Validation

```{R}
library(caret)

Nonparametricdata <- dataset %>% select(-Population)

# Fitting Non-Parametric Classifier. 

knn_fit <- knn3(factor(Pop.Density.Level == 1, levels = c("TRUE","FALSE")) ~ Income + Gini + ICU.Beds + Income + GDP, data = Nonparametricdata, k = 5)
y_hat_knn <- predict(knn_fit, Nonparametricdata)
y_hat_knn %>% head(6)

data.frame(y_hat_knn, names = rownames(Nonparametricdata))%>% arrange(names) %>% head(6)

class_diag(y_hat_knn[,1], Nonparametricdata$Pop.Density.Level, positive = 1)

# Confusion Matrix.

table(truth = factor(Nonparametricdata$Pop.Density.Level == 1, levels = c("TRUE","FALSE")), prediction = factor(y_hat_knn[,1]>.5, levels = c("TRUE","FALSE")))

# K-Fold CV. 

k = 5
data <- Nonparametricdata[sample(nrow(Nonparametricdata)),]
folds <- cut(seq(1:nrow(Nonparametricdata)), breaks = k, labels = F) 
diags <- NULL
for(i in 1:k){
  train <- data[folds!=i,] 
  test <- data[folds==i,]
  truth <- test$Pop.Density.Level
  fit <- knn3(Pop.Density.Level~Income + Gini + ICU.Beds + Income + GDP, data=train)
  probs <- predict(fit, newdata = test)[,2]
  diags <- rbind(diags, class_diag(probs, truth, positive=1))
}
summarize_all(diags,mean)

```

When predicting the data using knn, we get an AUC value of around 0.83. When predicting the data using K-Fold CV, we get an AUC value of around 0.70. Since the AUC values dropped in the CV, there seems to be a sign of over fitting. My model is a relatively strong predictor of new observations. From our confusion matrix, we can see that the majority of the predictions are correct. We can see that the linear model is stronger than the non linear model. 

### Regression/Numeric Prediction

```{R}
NumericData <- dataset %>% select(Population, Income, GDP, Gini)

# Regression Model. 

fit <- lm(Population ~ Income + GDP + Gini, data = NumericData)
yhat <- predict(fit)

# MSE.

mean((NumericData$Population-yhat)^2)

# K-Fold CV. 

k = 5 
data <- NumericData[sample(nrow(NumericData)),] 
folds <- cut(seq(1:nrow(NumericData)),breaks=k,labels=F) 
diags <- NULL
for(i in 1:k){
  train <- data[folds!=i,]
  test <- data[folds==i,]
  fit <- lm(Population~.,data = train)
  yhat <- predict(fit, newdata=test)
  diags <- mean((test$Population-yhat)^2) 
}
 
mean(diags) 
```

For Regression Prediction, I used a linear model. I got a super high error from the MSE and there seems to be signs of over fitting as the CV value is less than the MSE value. This isn't a good model for this type of data. It could be improved with better suited variables. 

### Python 

```{R}
library(reticulate)
use_python("/usr/bin/python3", required = F)
#py_install(packages = "matplotlib")

x <- dataset$Population
y <- dataset$Gini
```
This plot shows a positive, linear trend between the population size and the death rate of a state. This means that the death rate increases with population size. This may be because the lack of supply for health care supplies and services vs the demand. The hospitals in the more populated areas may be more overwhelmed by the demand than those in less populated areas. This may lead to people dying from there not being help available to them. The virus may be more susceptible to being spread in more densely populated areas. This relationship is to be expected. 

```{python}
import matplotlib.pyplot as plt
x = r.x
y = r.y
plt.scatter(x,y)
```
This plot shows that the death rate increases with testing rate with states with more than half the population being testing having a higher death rate than states with less than half the population tested. This relationship is rather unexpected as you would think that people who got tested would be taking more precautions against the virus. This relationship may be because states with higher death rates are pushing harder against testing leading to testing being more available to the public.

```{r}
x <- py$x
y <- py$y

plot(x, y, main = "Python to R Plot", col = "darkseagreen4", pch = 20)
```

In this example, I used r. to change 2 columns of my data into python objects and made a plot out of them using the matplotlib package. Then I converted them back into R objects using py$ and make the same plot using base R. 

### Concluding Remarks

In conclusion, I found that this study confirmed what I thought all along about the relationship between wealth / resource distribution and a state's population. 

